---
title: "hdt5"
author: "Elean Rivas, Javier Alvarez"
date: "2023-03-17"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### 1. Use los mismos conjuntos de entrenamiento y prueba que utilizó en las dos hojas anteriores. 

```{r warning=FALSE, unload=TRUE}
#Librerias a utilizar
library(e1071)
library(caret)
library(magrittr)
library(plyr)
library(dplyr)
library(cluster)
library(mclust)
library(fpc)
library(NbClust)
library(factoextra)
library(readr)
library(ppclust)
library(randomForest)
library(ggplot2)
library(broom)
library(ggpubr)
library(corrplot)
library(mctest)
library(Amelia)
library(caretEnsemble)
library(psych)
library(mice)
library(GGally)
library(tidyverse)
library(rpart)
library(h2o)
#base de datos a utilzar
datos <- read.csv("train.csv")
datosCasas <- datos[,-c(1,7)]
```

###  2. Elabore un modelo de bayes ingenuo (naive bayes) utilizando el conjunto de entrenamiento y explique los resultados a los que llega. El experimento debe ser reproducible por lo que debe fijar que los conjuntos de entrenamiento y prueba sean los mismos siempre que se ejecute el código. 

### 3. Haga un modelo de clasificacion, use la variable categórica que hizo con el precio de las casas

```{r, echo=FALSE}
getmode <- function(v){
  v=v[nchar(as.character(v))>0]
  uniqv <- unique(v)
  uniqv[which.max(tabulate(match(v, uniqv)))]
}
for (cols in colnames(datosCasas)) {
  if (cols %in% names(datosCasas[,sapply(datosCasas, is.numeric)])) {
    datosCasas<-datosCasas%>%mutate(!!cols := replace(!!rlang::sym(cols), is.na(!!rlang::sym(cols)), mean(!!rlang::sym(cols), na.rm=TRUE)))
  }
  else {
    datosCasas<-datosCasas%>%mutate(!!cols := replace(!!rlang::sym(cols), !!rlang::sym(cols)=="", getmode(!!rlang::sym(cols))))
  }
}
datosCasas <- datosCasas[,-29]
datosCasas <- datosCasas[,-29]
datosCasas <- datosCasas[,-29]
datosCasas <- datosCasas[,-29]
datosCasas <- datosCasas[,-30]
datosCasas <- datosCasas[,-24]
datosCasas <- datosCasas[,-50]
#View(datosCasas)
porciento <- 70/100
#variable que clasifica las casas
datosCasas$clasificacion <- ifelse(datosCasas$SalePrice <= 251000, "Economicas", ifelse(datosCasas$SalePrice <= 538000, "Intermedias", ifelse(datosCasas$SalePrice <= 755000, "Caras")))
datosCasas$y <- factor(datosCasas$clasificacion)
set.seed(123)
trainRowsNumber<-sample(nrow(datosCasas),porciento*nrow(datosCasas))
train<-datosCasas[trainRowsNumber,]
test<-datosCasas[-trainRowsNumber,]
#modelo de naivebayes
modelo<-naiveBayes(train$y~., data=train)
modelo
```
Con esto puede observarse que las probabilidades a priori obtenidas son: caras 0.4897%, economicas 85.01% e intermedias 14.50%.

Es decir, la mayoría de casas se encuentra en un rango de precio de venta económico, seguido por las casas con un precio de venta intermedio y por último se encuentran aquellas con un precio de venta elevado.


### 4. Utilice  el  modelo  con  el  conjunto  de  prueba  y  determine  la  eficiencia  del  algoritmo  para clasificar.
```{r}
prediction <- predict(modelo, test)
prediction
```

Se realiza la prediccion empleando el modelo y set de prueba para la evaluacion de eficiencia del algoritmo. 



### 5. Analice los resultados del modelo de regresion, que tan bien le fue prediciendo?


### 6.Compare los resultados con el modelo de regresión lineal y el árbol de regresión que hizo en las hojas pasadas. ¿Cuál funcionó mejor?


### 7. Haga  un  análisis  de  la  eficiencia  del  algoritmo  usando  una  matriz  de  confusión.  Tenga  en cuenta la efectividad, donde el algoritmo se equivocó más, donde se equivocó menos y la importancia que tienen los errores.
```{r}
library(caret)
cfm <- confusionMatrix(prediction,as.factor(test$clasificacion))
cfm
```

Basado en la matriz de confusion realizada a partir de la prediccion y el set de prueba, la precision del modelo
para realizar predicciones de 0.8656 o 86.56%. El modelo presenta sensibilidad, especificidad y exactitud balanceda,
aceptables para la clasificacion de caras y economicas, sin embargo en la clasificacion de economicas estos indicadores
presentan menor eficiencia. 


### 8. Analice el modelo. Explique si hay sobreajuste (overfitting) o no.
Al tener un nivel de accurancy alto y porcentajes de comportamiento similares, se puede llegar a pensar que el modelo pudo a ver sufrido un sobreajuste, pero esto se puede ver realmente comparandolo con otro conjunto de datos para comprobar si hubo o no hubo sobreajuste, para esto usaremos la validacion cruzada 


### 9. Haga  un  modelo  usando  validación  cruzada,  compare  los  resultados  de  este  con  los  del modelo anterior. ¿Cuál funcionó mejor?
```{r}
library(h2o)
h2o.no_progress()
h2o.init()
train$SalePrice <- factor(train$SalePrice)
y <- "SalePrice"
x <- setdiff(names(train), y)
train.h2o <- train %>%
  mutate_if(is.factor, factor, ordered = FALSE) %>%
  as.h2o()
nb.h2o <- h2o.naiveBayes(
  x = x,
  y = y,
  training_frame = train.h2o,
  nfolds = 10,
  laplace = 0
)
confusionMatrixCV <- h2o.confusionMatrix(nb.h2o)
```

matriz de confusion para modelo de validacion cruzada
```{r}
confusionMatrixCV
```

### 10. Compare la eficiencia del algoritmo con el resultado obtenido con el árbol de decisión (el de clasificación). ¿Cuál es mejor para predecir? ¿Cuál se demoró más en procesar?

En comparacion con el algortimo de clasificacion y de naive bayes, el arbol de desicion tiene una mejor rendimiento y es mejor en la prediccion de los datos.
Ahora con el tiempo naive bayes fue mas rapido que la validacion cruzada, aunque esto depende tambien de la cantidad de datos que tengamos y tambien de las librerias usadas para el modelo. 



